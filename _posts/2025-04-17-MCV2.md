---
title: Model Comprehension Version two
author: Thomas
date: 2025-04-17 00:00:00 -5:00
category: Projects
tags: []
description: This project goal is to take diagrams and find how visual dense the diagram is, using computer vision techniques like OCR and open_cv methods.
published: true
pin: true
toc: true
---

# Model Comprehension Version 2

> This project relates to its [predecessor Model Comprehension V1](https://tomicgun.github.io/posts/MCV1/) in that post I cover alot of the background information and purpose of this project.
> and cover the background and reason why I created this project.
 {: .prompt-info}
>

## Summary
This project was initiated in the summer of last year with the objective to determine what makes a UML diagram a good UML diagram. 
This simple questions had many complex facets to it. One question was whether a more dense or less dense diagram was better. 
Thus, this algorithm was made to automatically find the density of UML diagrams based of average pixel distance between significant semantic 
and diagrammatic points on the diagram or points of interest (POI). 

This program was created to fix many of the issues in its predecessor. The main goals was to find and create better solution to finding boxes,nodes and
text of the boxes on various UML diagrams. Then also fix any bugs, errors or other faults found in the intervening months from the initial creation.
Also fix the voronoi tesselation method such that it no longer find one or none voronoi regions. We also wanted go about in a formal way testing to see if
the new version is actually better than its old version. Finally make the new version efficient, consistent and accurate though code optimizations, documentation
and refactoring.

## Design and Solution
When begin this version I took a step back and identified my main issues I wanted to focus on where:
1. Fixing the Voronoi Tesselation Method (Particular thorn in my side and first thing I wanted to fix)
2. Find better ways to find nodes/boxes and text
3. Find a better way to cluster without needing background data
4. Fix various bug issues and refactor spaghetti code
5. Test v2 code vs. v1 code and make sure we are actually improving the project

This time I would be working with a friend that help me throughout this process with design and epically refactoring
the code into a more readable and maintainable state. We decided that we were going to completely recreate our clustering method
and method that finds the boxes/text of the diagram. We pivoted away from using open_cv as our primary library used to using
optical character recognition (OCR) library called pymupdf. We than had a backup method based of open_cv but used a much better
method that was more capable at finding boxes and text when OCR fails to find sufficient data. 

We also decided to use mean shift clustering instead of k-means clustering the main reason was that the k-means needed outside
information provided to the program that would tell k-means how many cluster it needed to make, while mean shift clustering 
would figure out how many cluster were needed automatically, and with no outside information.

This coupled with many bug and clarity fixes should put this program in a much more capable spot that it was when I initially
wrote it out.

![Activity Diagram of our project]()

## Implementation / Main Problems

After spending a week designing we set out on our objectives. The initial OCR library we used was called simple ocr based of pytesseracts and pyvission
However this library had a serious memory leak and machine requirement with only the most serious beast of pc being able to run it. Thus we pivoted to
pymupdf a much more efficient and faster library that required less dependency like cuda and way less memory and virtual ram. This OCR library was much better
and even allowed the integration of pre-trained models that where particularly good at picking out certain text and characters.

![Example of OCR](assets/images/y17a5s4d1.png)

After this I created a back-up method to find text and boxes when the OCR method failed. This fallback only happened occasionally
especially on very large very low resolution images. I still used open_cv for this method, but opted to instead of using the find contour method
in open_cv use the getStructural elements data to find structural elements of our diagram, then dilate these sections and then use the find_contour method.
I would then filter out especially small points to filter out any outlier points and this method gave back a much better much more accurate results.

![Show a example of the rollback method](assets/images/RollbackMethodExample.png)

After we completed this we decided that clustering was mostly unnecessary at this point. Most our results and center point sets where small mean of 45 median 42
however if a center point set result from the OCR or rollback was larger than 100 we decided to cluster this set using mean shift clustering which was very easy to 
implement. This clustering would get the data set back within range of the median and no longer be a outlier.

![Show example of new clustering graphs]()

Finally, we fixed various bugs and issues most clarity related issues but two critical ones where found and fixed. One was the way I calculated distance
and accidentally filtered out points that had the same x or y and not same x and same y. Thus filtering out more data that I should have. I also managed to fix
the issue with the voronoi tesselation method. The method itself was not at fault but the way I defined my bounding box was, and when I was able to accurate
count pixels and get the entire pixel size of our diagrams allowed for a accurate bounding box and much better results from the voronoi method.

![example of better voronoi method](assets/images/GoodBadVoronoi.png)

This wrapped up of all of our big issues and brings this project up to the level of quality I initially had for it. However, I still had some extra time
and decided to plan some more extra features.

## Step-by-step process
1. For every pdf file it creates a png file
2. For every png file it then runs a optical character recognition (OCR)  method
3. If the OCR returns less than 6 POIs it then runs a open cv method
4. The algorithm then uses the method that returns the most POI’s.
5. If the number of POI’s is larger than 100 it will use mean shift clustering to reduce the number of POI’s
6. The data from the above steps is used in a custom voronoi method to find voronoi center points. 
7. These voronoi center points are used to calculate average distance, and standard deviation of the distances.

## Testing
Our final step was to compare the old and new version in a head-to-head test to see if version two is truly better than version one. We design a
simply test to see which one was better. Our proces was to select 10 diagrams by hand and 10 diagrams randomly then do all 20 diagrams 
by hand in a procedure defined in earlier research this was considered our control group. We then had the two version run and
the same 20 diagrams, and we compared the results both visual through the graphs and by absolute error from the by hand method. Visual the graphs where much more
accurate and clear in version two than in version one and more importantly the absolute error for version two was much lower than version one by the
tune of the thousands of pixels. This confirmed that not only was Voronoi was necessary but that version two was better than version one. Most importantly
the failure rate of version two was a staggering zero percent compared to version one's failure rate of 22% or 152 diagrams.

![Absolute error graphs](assets/images/4Graphs.png)

## Next Steps

I plan for the few remaining weeks to do three things
1. Make this program a CLI tool that can be easily customized to fit all user needs
2. Create proper documentation and JAVA docs such that future researchers can use this program and maintain it without needing to decipher it

In the next few weeks I plan to complete these features, and will make a further update post when I complete them

## Conclusion

#TODO Write conclusion







